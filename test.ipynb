{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from worst_case_implementation import VecDBWorst\n",
    "from hnsw import VecDBhnsw\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from vec_db import VecDB\n",
    "# from inverted_file_index import VecDBIF\n",
    "from math import ceil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbor IDs: [[ 55 716 661 111 315]]\n",
      "Distances: [[0.24350546 0.3126167  0.38367575 0.4391805  0.5038757 ]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataset for demonstration\n",
    "data = np.random.random((1000, 10)).astype(np.float32)\n",
    "\n",
    "# Create an HNSW index\n",
    "index = faiss.IndexHNSWFlat(10, 32)  # 10-dimensional vectors, 32 neighbors per point\n",
    "index.add(data)\n",
    "\n",
    "# Query for nearest neighbors\n",
    "query = np.random.random((1, 10)).astype(np.float32)\n",
    "distances, ids = index.search(query, k=5)\n",
    "\n",
    "print(\"Nearest neighbor IDs:\", ids)\n",
    "print(\"Distances:\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cal_score(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    cosine_similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUERY_SEED_NUMBER = 10\n",
    "DB_SEED_NUMBER = 50\n",
    "\n",
    "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
    "query = rng.random((1, 70), dtype=np.float32)\n",
    "\n",
    "num_records = 10**7*2\n",
    "rng = np.random.default_rng(DB_SEED_NUMBER)\n",
    "records_np = rng.random((num_records, 70), dtype=np.float32)\n",
    "\n",
    "new_db = True\n",
    "\n",
    "# calculate the score for each record and sort them, write them to a file\n",
    "scores = []\n",
    "for i in range(100000):\n",
    "    score = _cal_score(query, records_np[i])\n",
    "    scores.append((score, i))\n",
    "    \n",
    "scores.sort(key=lambda x: x[0])\n",
    "with open(\"scores.txt\", \"w\") as f:\n",
    "    for score, index in scores:\n",
    "        f.write(str(index) + \",\" + str(score) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "# use faiss to build hnsw index\n",
    "num_records = 10**7*2\n",
    "rng = np.random.default_rng(DB_SEED_NUMBER)\n",
    "records_np = rng.random((num_records, 70), dtype=np.float32)\n",
    "index = faiss.IndexHNSWFlat(70, 16)\n",
    "index.hnsw.efConstruction = 200\n",
    "index.add(records_np)\n",
    "faiss.write_index(index, \"hnsw.index\")\n",
    "\n",
    "# generate the query\n",
    "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
    "query = rng.random((1, 70), dtype=np.float32)\n",
    "\n",
    "# use faiss to search\n",
    "index = faiss.read_index(\"hnsw.index\")\n",
    "D, I = index.search(query, 100)\n",
    "print(I)\n",
    "print(D)\n",
    "\n",
    "# compare the result with the result from brute force\n",
    "scores = []\n",
    "for i in range(100000):\n",
    "    score = _cal_score(query, records_np[i])\n",
    "    scores.append((score, i))\n",
    "    \n",
    "scores.sort(key=lambda x: x[0])\n",
    "print(scores[:100])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataset for demonstration\n",
    "data = np.random.random((1000, 10)).astype(np.float32)\n",
    "\n",
    "# Create an HNSW index\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(data)\n",
    "index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "# Query for nearest neighbors\n",
    "query = np.random.random((1, 10)).astype(np.float32)\n",
    "ids, distances = index.knnQuery(query, k=5)\n",
    "\n",
    "print(\"Nearest neighbor IDs:\", ids)\n",
    "print(\"Distances:\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6 5\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "y = 6\n",
    "z = x\n",
    "\n",
    "# to let z be a reference to x instead of a copy of x, we can use the following\n",
    "z = x\n",
    "x = 7\n",
    "\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 2), ('c', 4), ('a', 5)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'a': 5, 'b': 2, 'c': 4}\n",
    "sorted_dict = sorted(dictionary.items(), key=lambda x: x[1])\n",
    "print(sorted_dict)\n",
    "first_value = sorted_dict[0][1]\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0,5):\n",
    "#     print(i)\n",
    "\n",
    "# now if we want to print in reverse order\n",
    "for i in range(5,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Annotated\n",
    "\n",
    "l_of_dict: List[Dict[int, chr]] = [{1: 'a', 2: 'b'}, {3: 'c', 4: 'd'}, {5: 'e', 6: 'f', 7: 'g'}]\n",
    "\n",
    "l_of_dict.append({})\n",
    "print(len(l_of_dict))\n",
    "print(l_of_dict[0].get(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3, 4, 5]\n",
    "\n",
    "for i in l[:3]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{4: 4}, {3: 3}, {2: 2}, {1: 1}, {0: 0}]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(5):\n",
    "    l.insert(0, {i: i})\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "l1= [1,2,3,4,5]\n",
    "l2 = [6,7,8,9,10]\n",
    "l3 = l1 + l2\n",
    "print(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5}\n"
     ]
    }
   ],
   "source": [
    "a = dict()\n",
    "a[0] = 5\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1]}\n",
      "{0: [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "# now we will make a dictionary where the key is integer and value is a list of integers\n",
    "b = dict()\n",
    "# now we want to append only one value to the list\n",
    "b[0] = b.get(0, []) + [1]\n",
    "print(b)\n",
    "\n",
    "b[0] = b.get(0, []) + [2]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rufai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  2.]\n",
      " [ 1.  2.]]\n",
      "------------------\n",
      "[1]\n",
      "------------------\n",
      "[array([10.,  2.]), array([1., 2.])]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the kmeans algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "class vector:\n",
    "    def __init__(self, id, vect) -> None:\n",
    "        self.id = id\n",
    "        self.vect = vect\n",
    "        self.centroid = None # the centroid that this vector belongs to\n",
    "\n",
    "\n",
    "Vecs = []\n",
    "Vecs.append(vector(0, [1, 2]))\n",
    "Vecs.append(vector(1, [1, 4]))\n",
    "Vecs.append(vector(2, [1, 0]))\n",
    "Vecs.append(vector(3, [10, 2]))\n",
    "Vecs.append(vector(4, [10, 4]))\n",
    "Vecs.append(vector(5, [10, 0]))\n",
    "\n",
    "# apply kmeans on the vectors\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(np.array([v.vect for v in Vecs]))\n",
    "\n",
    "print(kmeans.cluster_centers_)\n",
    "print(\"------------------\")\n",
    "#  now we need to find the n closest centroids to the vector\n",
    "n = 2\n",
    "v = Vecs[0]\n",
    "print(kmeans.predict([v.vect]))\n",
    "print(\"------------------\")\n",
    "\n",
    "nearest_centroids = sorted(kmeans.cluster_centers_, key=lambda x: np.linalg.norm(x - v.vect), reverse= True)[:n]\n",
    "print(nearest_centroids)\n",
    "print(\"------------------\")\n",
    "# another way to do it is to use the kneighbors function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'one'), (2, 'two'), (5, 'five'), (10, 'ten')]\n",
      "1\n",
      "[(-10, 'ten'), (-2, 'two'), (-5, 'five'), (-1, 'one')]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "heap = []\n",
    "\n",
    "# heapify function converts a regular list to a heap\n",
    "heapq.heapify(heap)\n",
    "heapq.heappush(heap, (1, 'one'))\n",
    "heapq.heappush(heap, (10, 'ten'))\n",
    "heapq.heappush(heap, (5, 'five'))\n",
    "heapq.heappush(heap, (2, 'two'))\n",
    "print(heap)\n",
    "\n",
    "# print only the first element of the heap\n",
    "print(heap[0][0])\n",
    "\n",
    "\n",
    "# now we will try to create another heap that is sorted descendingly\n",
    "# we can do that by multiplying the key by -1\n",
    "heap2 = []\n",
    "heapq.heapify(heap2)\n",
    "heapq.heappush(heap2, (-1, 'one'))\n",
    "heapq.heappush(heap2, (-10, 'ten'))\n",
    "heapq.heappush(heap2, (-5, 'five'))\n",
    "heapq.heappush(heap2, (-2, 'two'))\n",
    "print(heap2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "C:\\msys64\\mingw64\\bin\\python3.exe: No module named pip3\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Python311\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Nothing changed\n",
    "!conda update sklearn\n",
    "\n",
    "# Error cannot find pip3\n",
    "!python3 -m pip3 install --upgrade sklearn\n",
    "\n",
    "# From the logs is installing 0.22\n",
    "!pip install sklearn --upgrade\n",
    "\n",
    "\n",
    "!conda install scikit-learn -y\n",
    "\n",
    "# Stuck forever at: Solving environment\n",
    "!conda config --append channels conda-forge\n",
    "!conda install scikit-learn=0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uinstall pip threadpoolctl\n",
    "# uninstall sklearn \n",
    "# install sklearn\n",
    "\n",
    "# pip freeze | grep scikit-learn  --> google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '10k/centroids.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# now we will try to load data from a pickle file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10k/centroids.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '10k/centroids.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# now we will try to load data from a pickle file\n",
    "data = pickle.load(open('10k/centroids.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "person1 = [1, 2, 3, 4, 5]\n",
    "preson2 = [6, 7, 8, 9, 10]\n",
    "\n",
    "pickleFile = open(\"person1.pkl\",\"wb\")\n",
    "pickle.dump(person1, pickleFile) # put\n",
    "pickle.dump(preson2, pickleFile) # put\n",
    "\n",
    "\n",
    "\n",
    "pickleFile = open(\"person1.pkl\",\"rb\")\n",
    "\n",
    "# looad from the file until we reach the end of the file\n",
    "while True:\n",
    "    try:\n",
    "        print(pickle.load(pickleFile))\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "# print(persona)\n",
    "# print(personb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [5, 6], [8, 9]]\n"
     ]
    }
   ],
   "source": [
    "matrix = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "# let's remove the first element of each row without using a for loop\n",
    "matrix = [row[1:] for row in matrix]\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "v = [1] + [2,3,4]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'example_key': 'example_value_1', 'numbers': [1, 2, 3, 4]}, {'example_key': 'example_value_2', 'numbers': [5, 6, 7, 8]}]\n"
     ]
    }
   ],
   "source": [
    "data_list = [\n",
    "    {'example_key': 'example_value_1', 'numbers': [1, 2, 3, 4]},\n",
    "    {'example_key': 'example_value_2', 'numbers': [5, 6, 7, 8]},\n",
    "    # Add more dictionaries as needed\n",
    "]\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'example.pkl'\n",
    "\n",
    "# Open the file in binary write mode ('wb')\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Use a for loop to iterate through the list and dump each dictionary\n",
    "    for data in data_list:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "# Open the file in binary read mode ('rb')\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Use a for loop to iterate through the list and load each dictionary\n",
    "    for i in range(len(data_list)):\n",
    "        data_list[i] = pickle.load(file)\n",
    "\n",
    "# Print the loaded data\n",
    "print(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'hello.txt' copied to 'dest'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_files(src_folder, dest_folder):\n",
    "    # Make sure the source folder exists\n",
    "    if not os.path.exists(src_folder):\n",
    "        print(f\"Source folder '{src_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Make sure the destination folder exists, create it if necessary\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    # Get a list of all files in the source folder\n",
    "    files = os.listdir(src_folder)\n",
    "\n",
    "    # Copy each file from the source folder to the destination folder\n",
    "    for file in files:\n",
    "        src_path = os.path.join(src_folder, file)\n",
    "        dest_path = os.path.join(dest_folder, file)\n",
    "        shutil.copy(src_path, dest_path)\n",
    "        print(f\"File '{file}' copied to '{dest_folder}'.\")\n",
    "\n",
    "# Example usage:\n",
    "source_folder = 'src'\n",
    "destination_folder = 'dest'\n",
    "\n",
    "copy_files(source_folder, destination_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's append in the file in the dest folder\n",
    "file = open(f'{destination_folder}/hello.txt', 'a')\n",
    "file.write('doaa magdy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
